{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dotenv\n",
    "import mlflow\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "import plotly.graph_objects as go\n",
    "from huggingface_hub import login\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from utils import calculate_sklearn_metrics, TrainingConfig\n",
    "\n",
    "dotenv.load_dotenv(\"../../.env\")\n",
    "\n",
    "token = os.environ[\"HF_TOKEN\"]\n",
    "login(token=token)\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"rosstat_forecasting\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: 4140 строк\n",
      "Валидационная выборка: 828 строк\n",
      "Тестовая выборка: 828 строк\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../../data/rosstat/processed'\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_dir, 'train/data.csv'))\n",
    "val_df = pd.read_csv(os.path.join(data_dir, 'val/data.csv'))\n",
    "test_df = pd.read_csv(os.path.join(data_dir, 'test/data.csv'))\n",
    "\n",
    "print(f\"Обучающая выборка: {train_df.shape[0]} строк\")\n",
    "print(f\"Валидационная выборка: {val_df.shape[0]} строк\")\n",
    "print(f\"Тестовая выборка: {test_df.shape[0]} строк\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    train_df.rename(columns={\"nominal_wage\": \"target\"}),\n",
    "    id_column=\"code\",\n",
    "    timestamp_column=\"date\",\n",
    ")\n",
    "val_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    val_df.rename(columns={\"nominal_wage\": \"target\"}),\n",
    "    id_column=\"code\",\n",
    "    timestamp_column=\"date\",\n",
    ")\n",
    "test_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    test_df.rename(columns={\"nominal_wage\": \"target\"}),\n",
    "    id_column=\"code\",\n",
    "    timestamp_column=\"date\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"../models/auto_ml_single_target\"\n",
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to '/home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.12.7\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #60~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Mar 28 16:09:21 UTC 2\n",
      "CPU Count:          12\n",
      "GPU Count:          1\n",
      "Memory Avail:       22.34 GB / 30.95 GB (72.2%)\n",
      "Disk Space Avail:   158.26 GB / 233.67 GB (67.7%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': False,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': {'Chronos': [{'ag_args': {'name_suffix': 'ZeroShot'},\n",
      "                                  'model_path': 'bolt_small'},\n",
      "                                 {'ag_args': {'name_suffix': 'FineTuned'},\n",
      "                                  'fine_tune': True,\n",
      "                                  'model_path': 'bolt_small'}],\n",
      "                     'DirectTabular': {},\n",
      "                     'RecursiveTabular': {},\n",
      "                     'TemporalFusionTransformer': {}},\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'verbosity': 4}\n",
      "\n",
      "Provided train_data has 4140 rows, 69 time series. Median time series length is 60 (min=60, max=60). \n",
      "Provided tuning_data has 828 rows, 69 time series. Median time series length is 12 (min=12, max=12). \n",
      "\tSetting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.\n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        []\n",
      "\t\tcontinuous (float): ['capital_labor_ratio_change', 'capital_productivity_change', 'fixed_assets...arable_prices', 'labor_productivity', 'high_productivity_jobs', 'machinery_sh..._total_assets', ...]\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "Removing existing cached predictions file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-05-01 23:38:40\n",
      "Models that will be trained: ['RecursiveTabular', 'DirectTabular', 'ChronosZeroShot[bolt_small]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer']\n",
      "Training timeseries model RecursiveTabular. \n",
      "Shortening all series to at most 14507\n",
      "train_df shape: (3174, 20), val_df shape: (138, 20)\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/RecursiveTabular/tabular_predictor\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.12.7\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #60~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Mar 28 16:09:21 UTC 2\n",
      "CPU Count:          12\n",
      "Memory Avail:       22.09 GB / 30.95 GB (71.4%)\n",
      "Disk Space Avail:   158.26 GB / 233.67 GB (67.7%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/RecursiveTabular/tabular_predictor\"\n",
      "Train Data Rows:    3174\n",
      "Train Data Columns: 17\n",
      "Tuning Data Rows:    138\n",
      "Tuning Data Columns: 17\n",
      "Label Column:       y\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22616.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.42 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['lag1', 'lag2', 'lag3', 'lag4', 'lag5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['lag1', 'lag2', 'lag3', 'lag4', 'lag5', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.42 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.7761\t = Validation score   (-mean_absolute_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBM': 1.0}\n",
      "\t-0.7761\t = Validation score   (-mean_absolute_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 0.71s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 61133.7 rows/s (138 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/RecursiveTabular/tabular_predictor\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 0.776516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: 69 time series (100.0%) are shorter than 12 and cannot be predicted by RecursiveTabular. Fallback model SeasonalNaive is used for these time series.\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250501_203841SeasonalNaive\"\n",
      "Warning: No path was specified for model, defaulting to: /home/nikita/projects/time_series_analysis/code_dir/rosstat/chronos/AutogluonModels/ag-20250501_203841\n",
      "Shortening all time series to at most 2500\n",
      "\t-0.1321       = Validation score (-WQL)\n",
      "\t0.75    s     = Training runtime\n",
      "\t0.85    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. \n",
      "Shortening all series to at most 14495\n",
      "train_df shape: (4002, 20), val_df shape: (138, 20)\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/DirectTabular/tabular_predictor\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.12.7\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #60~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Mar 28 16:09:21 UTC 2\n",
      "CPU Count:          12\n",
      "Memory Avail:       21.33 GB / 30.95 GB (68.9%)\n",
      "Disk Space Avail:   158.26 GB / 233.67 GB (67.7%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/DirectTabular/tabular_predictor\"\n",
      "Train Data Rows:    4002\n",
      "Train Data Columns: 17\n",
      "Tuning Data Rows:    138\n",
      "Tuning Data Columns: 17\n",
      "Label Column:       y\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21839.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['lag1', 'lag2', 'lag3', 'lag4', 'lag5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['lag1', 'lag2', 'lag3', 'lag4', 'lag5', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.0407\t = Validation score   (-pinball_loss)\n",
      "\t13.0s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBM': 1.0}\n",
      "\t-0.0407\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 13.55s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3308.2 rows/s (138 batch size)\n",
      "Disabling calibration for metric `pinball_loss` due to having fewer than 1000 rows of validation data for calibration, to avoid overfitting (138 rows). Force calibration via specifying `calibrate=True`. (calibrate='auto')\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/DirectTabular/tabular_predictor\")\n",
      "Shortening all series to at most 14497\n",
      "Shortening all series to at most 14495\n",
      "\t-0.1413       = Validation score (-WQL)\n",
      "\t13.58   s     = Training runtime\n",
      "\t0.23    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_small]. \n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "\t-0.1342       = Validation score (-WQL)\n",
      "\t0.88    s     = Training runtime\n",
      "\t0.87    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. \n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Transformers logging is turned on during fine-tuning. Note that losses reported by transformers may not correspond to those specified via `eval_metric`.\n",
      "***** Running training *****\n",
      "  Num examples = 32,000\n",
      "  Num Epochs = 9,223,372,036,854,775,807\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1,000\n",
      "  Number of trainable parameters = 47,718,016\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n",
      "{'loss': 1583.8422, 'grad_norm': 313.2071838378906, 'learning_rate': 9e-06, 'epoch': 0.1}\n",
      "{'loss': 1214.9087, 'grad_norm': 318.7999572753906, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.2}\n",
      "{'loss': 834.0538, 'grad_norm': 4.52251672744751, 'learning_rate': 7e-06, 'epoch': 0.3}\n",
      "{'loss': 1097.831, 'grad_norm': 9.56881332397461, 'learning_rate': 6e-06, 'epoch': 0.4}\n",
      "{'loss': 1432.9372, 'grad_norm': 306.0831604003906, 'learning_rate': 5e-06, 'epoch': 0.5}\n",
      "{'loss': 1059.1722, 'grad_norm': 305.5460510253906, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.6}\n",
      "{'loss': 946.2955, 'grad_norm': 8.149438858032227, 'learning_rate': 3e-06, 'epoch': 0.7}\n",
      "{'loss': 1349.982, 'grad_norm': 280.2704772949219, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.8}\n",
      "{'loss': 1570.9041, 'grad_norm': 317.5302734375, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.9}\n",
      "{'loss': 1565.3486, 'grad_norm': 293.42169189453125, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples: Unknown\n",
      "  Batch size = 32\n",
      "{'eval_loss': 4.238907337188721, 'eval_runtime': 0.0308, 'eval_samples_per_second': 2239.281, 'eval_steps_per_second': 97.36, 'epoch': 1.0}\n",
      "Saving model checkpoint to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/transformers_logs/checkpoint-1000\n",
      "Configuration saved in /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/transformers_logs/checkpoint-1000/config.json\n",
      "Model weights saved in /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/transformers_logs/checkpoint-1000/model.safetensors\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 28.2506, 'train_samples_per_second': 1132.72, 'train_steps_per_second': 35.397, 'train_loss': 1265.5275234375, 'epoch': 1.0}\n",
      "\tSaving fine-tuned model to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt\n",
      "Configuration saved in /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model weights saved in /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/model.safetensors\n",
      "Removing transformers_logs directory /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/transformers_logs\n",
      "\t-0.1229       = Validation score (-WQL)\n",
      "\t29.52   s     = Training runtime\n",
      "\t0.01    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. \n",
      "\tbool_features: [], continuous_features: ['capital_labor_ratio_change', 'capital_productivity_change', 'fixed_assets_renewal_comparable_prices', 'high_productivity_jobs', 'machinery_share_in_total_assets', 'production_index_yoy', 'production_index_mom'], skewed_features: ['labor_productivity', 'investment_share_for_modernization']\n",
      "GluonTS logging is turned on during training. Note that losses reported by GluonTS may not correspond to those specified via `eval_metric`.\n",
      "\tTraining on device 'gpu'\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                           | Params | Mode  | In sizes                                                                           | Out sizes                    \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | TemporalFusionTransformerModel | 93.3 K | train | [[1, 64], [1, 64], [1, 1], [1, 1], [1, 66, 1], [1, 66, 0], [1, 64, 9], [1, 64, 0]] | [[[1, 2, 9]], [1, 1], [1, 1]]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "93.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "93.3 K    Total params\n",
      "0.373     Total estimated model params size (MB)\n",
      "180       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Epoch 0, global step 50: 'val_loss' reached 9859.69336 (best 9859.69336), saving model to '/home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/TemporalFusionTransformer/lightning_logs/version_0/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'val_loss' was not in top 1\n",
      "Epoch 2, global step 150: 'val_loss' was not in top 1\n",
      "Epoch 3, global step 200: 'val_loss' was not in top 1\n",
      "Epoch 4, global step 250: 'val_loss' reached 9133.13086 (best 9133.13086), saving model to '/home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/TemporalFusionTransformer/lightning_logs/version_0/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'val_loss' reached 7943.13672 (best 7943.13672), saving model to '/home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/TemporalFusionTransformer/lightning_logs/version_0/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'val_loss' reached 6236.48291 (best 6236.48291), saving model to '/home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/TemporalFusionTransformer/lightning_logs/version_0/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'val_loss' reached 5598.67725 (best 5598.67725), saving model to '/home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/TemporalFusionTransformer/lightning_logs/version_0/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'val_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'val_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'val_loss' reached 5586.31787 (best 5586.31787), saving model to '/home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/TemporalFusionTransformer/lightning_logs/version_0/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'val_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'val_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'val_loss' reached 5424.91211 (best 5424.91211), saving model to '/home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/TemporalFusionTransformer/lightning_logs/version_0/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'val_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'val_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'val_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'val_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'val_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'val_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'val_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'val_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'val_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'val_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'val_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'val_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'val_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'val_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'val_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'val_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'val_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'val_loss' was not in top 1\n",
      "Epoch 32, global step 1650: 'val_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'val_loss' was not in top 1\n",
      "Removing lightning_logs directory /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/TemporalFusionTransformer/lightning_logs\n",
      "\t-0.0674       = Validation score (-WQL)\n",
      "\t20.10   s     = Training runtime\n",
      "\t0.44    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['RecursiveTabular', 'DirectTabular', 'ChronosZeroShot[bolt_small]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer']\n",
      "Total runtime: 67.72 s\n",
      "Best model: TemporalFusionTransformer\n",
      "Best model score: -0.0674\n"
     ]
    }
   ],
   "source": [
    "config = TrainingConfig(\n",
    "    prediction_length=2,  # полгода\n",
    "    artifact_path=\"../models/auto_ml_single_target\",\n",
    ")\n",
    "\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=config.prediction_length, path=config.artifact_path, freq=\"MS\"\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    tuning_data=val_data,\n",
    "    verbosity=4,\n",
    "    hyperparameters={\n",
    "        \"DirectTabular\": {},\n",
    "        \"RecursiveTabular\": {},\n",
    "        \"TemporalFusionTransformer\": {},\n",
    "        \"Chronos\": [\n",
    "            {\"model_path\": \"bolt_small\", \"ag_args\": {\"name_suffix\": \"ZeroShot\"}},\n",
    "            {\n",
    "                \"model_path\": \"bolt_small\",\n",
    "                \"fine_tune\": True,\n",
    "                \"ag_args\": {\"name_suffix\": \"FineTuned\"},\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    enable_ensemble=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading predictor from path /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target\n"
     ]
    }
   ],
   "source": [
    "config = TrainingConfig(\n",
    "    prediction_length=2,  # полгода\n",
    "    artifact_path=\"../models/auto_ml_single_target\",\n",
    ")\n",
    "\n",
    "predictor = TimeSeriesPredictor.load(config.artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating leaderboard for all models trained\n",
      "Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found no cached predictions\n",
      "Prediction order: ['ChronosZeroShot[bolt_small]', 'ChronosFineTuned[bolt_small]', 'DirectTabular', 'RecursiveTabular', 'TemporalFusionTransformer']\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "\tFine-tuned checkpoint exists, setting model_path to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Shortening all series to at most 14497\n",
      "Shortening all series to at most 14495\n",
      "Warning: 69 time series (100.0%) are shorter than 12 and cannot be predicted by RecursiveTabular. Fallback model SeasonalNaive is used for these time series.\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250501_203949SeasonalNaive\"\n",
      "Warning: No path was specified for model, defaulting to: /home/nikita/projects/time_series_analysis/code_dir/rosstat/chronos/AutogluonModels/ag-20250501_203949\n",
      "Shortening all time series to at most 2500\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "WQL_test",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WQL_val",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pred_time_test",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pred_time_val",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fit_time_marginal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fit_order",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MASE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAPE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SQL",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d4ec6573-7abe-43d5-abbb-f4a36cbeb100",
       "rows": [
        [
         "0",
         "TemporalFusionTransformer",
         "-0.08987334570550833",
         "-0.06737305581964598",
         "0.04595828056335449",
         "0.4405398368835449",
         "20.096686601638794",
         "5",
         "-9871.897486413045",
         "-0.081069226691333",
         "-305844719.0387527",
         "-9871.897486413045",
         "-8428.169640700484"
        ],
        [
         "1",
         "ChronosFineTuned[bolt_small]",
         "-0.11955821915674293",
         "-0.12294163294688554",
         "0.07403326034545898",
         "0.008323431015014648",
         "29.522092580795288",
         "4",
         "-13770.490591032609",
         "-0.12074641929060208",
         "-421457372.7717697",
         "-13770.490591032609",
         "-11211.966630183173"
        ],
        [
         "2",
         "RecursiveTabular",
         "-0.13545793376836124",
         "-0.13212695564844051",
         "1.0486621856689453",
         "0.8512701988220215",
         "0.7481992244720459",
         "1",
         "-14335.877536231885",
         "-0.12199617218630113",
         "-551039619.1080436",
         "-14335.877536231885",
         "-12703.014848467432"
        ],
        [
         "3",
         "ChronosZeroShot[bolt_small]",
         "-0.1358277969483997",
         "-0.13419518914230044",
         "0.6608848571777344",
         "0.865938663482666",
         "0.8844354152679443",
         "3",
         "-14345.202858922103",
         "-0.12181289933274969",
         "-563494861.1769836",
         "-14345.202858922103",
         "-12737.699988992052"
        ],
        [
         "4",
         "DirectTabular",
         "-0.15711178293554554",
         "-0.1412532473463322",
         "0.23130536079406738",
         "0.23024964332580566",
         "13.57891845703125",
         "2",
         "-17287.149688632246",
         "-0.16102030617506943",
         "-608020958.8142077",
         "-17287.149688632246",
         "-14733.676027513586"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>WQL_test</th>\n",
       "      <th>WQL_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>fit_order</th>\n",
       "      <th>MASE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>SQL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TemporalFusionTransformer</td>\n",
       "      <td>-0.089873</td>\n",
       "      <td>-0.067373</td>\n",
       "      <td>0.045958</td>\n",
       "      <td>0.440540</td>\n",
       "      <td>20.096687</td>\n",
       "      <td>5</td>\n",
       "      <td>-9871.897486</td>\n",
       "      <td>-0.081069</td>\n",
       "      <td>-3.058447e+08</td>\n",
       "      <td>-9871.897486</td>\n",
       "      <td>-8428.169641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChronosFineTuned[bolt_small]</td>\n",
       "      <td>-0.119558</td>\n",
       "      <td>-0.122942</td>\n",
       "      <td>0.074033</td>\n",
       "      <td>0.008323</td>\n",
       "      <td>29.522093</td>\n",
       "      <td>4</td>\n",
       "      <td>-13770.490591</td>\n",
       "      <td>-0.120746</td>\n",
       "      <td>-4.214574e+08</td>\n",
       "      <td>-13770.490591</td>\n",
       "      <td>-11211.966630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RecursiveTabular</td>\n",
       "      <td>-0.135458</td>\n",
       "      <td>-0.132127</td>\n",
       "      <td>1.048662</td>\n",
       "      <td>0.851270</td>\n",
       "      <td>0.748199</td>\n",
       "      <td>1</td>\n",
       "      <td>-14335.877536</td>\n",
       "      <td>-0.121996</td>\n",
       "      <td>-5.510396e+08</td>\n",
       "      <td>-14335.877536</td>\n",
       "      <td>-12703.014848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChronosZeroShot[bolt_small]</td>\n",
       "      <td>-0.135828</td>\n",
       "      <td>-0.134195</td>\n",
       "      <td>0.660885</td>\n",
       "      <td>0.865939</td>\n",
       "      <td>0.884435</td>\n",
       "      <td>3</td>\n",
       "      <td>-14345.202859</td>\n",
       "      <td>-0.121813</td>\n",
       "      <td>-5.634949e+08</td>\n",
       "      <td>-14345.202859</td>\n",
       "      <td>-12737.699989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DirectTabular</td>\n",
       "      <td>-0.157112</td>\n",
       "      <td>-0.141253</td>\n",
       "      <td>0.231305</td>\n",
       "      <td>0.230250</td>\n",
       "      <td>13.578918</td>\n",
       "      <td>2</td>\n",
       "      <td>-17287.149689</td>\n",
       "      <td>-0.161020</td>\n",
       "      <td>-6.080210e+08</td>\n",
       "      <td>-17287.149689</td>\n",
       "      <td>-14733.676028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  WQL_test   WQL_val  pred_time_test  \\\n",
       "0     TemporalFusionTransformer -0.089873 -0.067373        0.045958   \n",
       "1  ChronosFineTuned[bolt_small] -0.119558 -0.122942        0.074033   \n",
       "2              RecursiveTabular -0.135458 -0.132127        1.048662   \n",
       "3   ChronosZeroShot[bolt_small] -0.135828 -0.134195        0.660885   \n",
       "4                 DirectTabular -0.157112 -0.141253        0.231305   \n",
       "\n",
       "   pred_time_val  fit_time_marginal  fit_order          MASE      MAPE  \\\n",
       "0       0.440540          20.096687          5  -9871.897486 -0.081069   \n",
       "1       0.008323          29.522093          4 -13770.490591 -0.120746   \n",
       "2       0.851270           0.748199          1 -14335.877536 -0.121996   \n",
       "3       0.865939           0.884435          3 -14345.202859 -0.121813   \n",
       "4       0.230250          13.578918          2 -17287.149689 -0.161020   \n",
       "\n",
       "            MSE           MAE           SQL  \n",
       "0 -3.058447e+08  -9871.897486  -8428.169641  \n",
       "1 -4.214574e+08 -13770.490591 -11211.966630  \n",
       "2 -5.510396e+08 -14335.877536 -12703.014848  \n",
       "3 -5.634949e+08 -14345.202859 -12737.699989  \n",
       "4 -6.080210e+08 -17287.149689 -14733.676028  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard = predictor.leaderboard(\n",
    "    test_data,\n",
    "    extra_metrics=['MASE', 'MAPE', 'MSE', 'MAE', 'SQL'],\n",
    ")\n",
    "leaderboard.rename(columns={'score_test': 'WQL_test', 'score_val': 'WQL_val'}, inplace=True)\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found no cached predictions\n",
      "Prediction order: {'ChronosFineTuned[bolt_small]'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFine-tuned checkpoint exists, setting model_path to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n"
     ]
    }
   ],
   "source": [
    "predictions = predictor.predict(val_data, \n",
    "                                model='ChronosFineTuned[bolt_small]',)\n",
    "                                # known_covariates=prediction_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found no cached predictions\n",
      "Prediction order: {'TemporalFusionTransformer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer']\n",
      "Prediction order: {'ChronosFineTuned[bolt_small]'}\n",
      "\tFine-tuned checkpoint exists, setting model_path to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]']\n",
      "Prediction order: {'RecursiveTabular'}\n",
      "Shortening all series to at most 14507\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular']\n",
      "Prediction order: {'ChronosZeroShot[bolt_small]'}\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular', 'ChronosZeroShot[bolt_small]']\n",
      "Prediction order: {'DirectTabular'}\n",
      "Shortening all series to at most 14497\n",
      "Shortening all series to at most 14495\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Found no cached predictions\n",
      "Prediction order: {'TemporalFusionTransformer'}\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer']\n",
      "Prediction order: {'ChronosFineTuned[bolt_small]'}\n",
      "\tFine-tuned checkpoint exists, setting model_path to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]']\n",
      "Prediction order: {'RecursiveTabular'}\n",
      "Shortening all series to at most 14507\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular']\n",
      "Prediction order: {'ChronosZeroShot[bolt_small]'}\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular', 'ChronosZeroShot[bolt_small]']\n",
      "Prediction order: {'DirectTabular'}\n",
      "Shortening all series to at most 14497\n",
      "Shortening all series to at most 14495\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Found no cached predictions\n",
      "Prediction order: {'TemporalFusionTransformer'}\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer']\n",
      "Prediction order: {'ChronosFineTuned[bolt_small]'}\n",
      "\tFine-tuned checkpoint exists, setting model_path to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]']\n",
      "Prediction order: {'RecursiveTabular'}\n",
      "Shortening all series to at most 14507\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular']\n",
      "Prediction order: {'ChronosZeroShot[bolt_small]'}\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular', 'ChronosZeroShot[bolt_small]']\n",
      "Prediction order: {'DirectTabular'}\n",
      "Shortening all series to at most 14497\n",
      "Shortening all series to at most 14495\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Found no cached predictions\n",
      "Prediction order: {'TemporalFusionTransformer'}\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer']\n",
      "Prediction order: {'ChronosFineTuned[bolt_small]'}\n",
      "\tFine-tuned checkpoint exists, setting model_path to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]']\n",
      "Prediction order: {'RecursiveTabular'}\n",
      "Shortening all series to at most 14507\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular']\n",
      "Prediction order: {'ChronosZeroShot[bolt_small]'}\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular', 'ChronosZeroShot[bolt_small]']\n",
      "Prediction order: {'DirectTabular'}\n",
      "Shortening all series to at most 14497\n",
      "Shortening all series to at most 14495\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Found no cached predictions\n",
      "Prediction order: {'TemporalFusionTransformer'}\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer']\n",
      "Prediction order: {'ChronosFineTuned[bolt_small]'}\n",
      "\tFine-tuned checkpoint exists, setting model_path to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]']\n",
      "Prediction order: {'RecursiveTabular'}\n",
      "Shortening all series to at most 14507\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular']\n",
      "Prediction order: {'ChronosZeroShot[bolt_small]'}\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular', 'ChronosZeroShot[bolt_small]']\n",
      "Prediction order: {'DirectTabular'}\n",
      "Shortening all series to at most 14497\n",
      "Shortening all series to at most 14495\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Found no cached predictions\n",
      "Prediction order: {'TemporalFusionTransformer'}\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer']\n",
      "Prediction order: {'ChronosFineTuned[bolt_small]'}\n",
      "\tFine-tuned checkpoint exists, setting model_path to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]']\n",
      "Prediction order: {'RecursiveTabular'}\n",
      "Shortening all series to at most 14507\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular']\n",
      "Prediction order: {'ChronosZeroShot[bolt_small]'}\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular', 'ChronosZeroShot[bolt_small]']\n",
      "Prediction order: {'DirectTabular'}\n",
      "Shortening all series to at most 14497\n",
      "Shortening all series to at most 14495\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['ChronosFineTuned[bolt_small]']\n",
      "Prediction order: {'TemporalFusionTransformer'}\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer']\n",
      "Prediction order: {'ChronosFineTuned[bolt_small]'}\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer']\n",
      "Prediction order: {'RecursiveTabular'}\n",
      "Warning: 69 time series (100.0%) are shorter than 12 and cannot be predicted by RecursiveTabular. Fallback model SeasonalNaive is used for these time series.\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250501_203958SeasonalNaive\"\n",
      "Warning: No path was specified for model, defaulting to: /home/nikita/projects/time_series_analysis/code_dir/rosstat/chronos/AutogluonModels/ag-20250501_203958\n",
      "Shortening all time series to at most 2500\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'RecursiveTabular']\n",
      "Prediction order: {'ChronosZeroShot[bolt_small]'}\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'RecursiveTabular', 'ChronosZeroShot[bolt_small]']\n",
      "Prediction order: {'DirectTabular'}\n",
      "Shortening all series to at most 14497\n",
      "Shortening all series to at most 14495\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Found no cached predictions\n",
      "Prediction order: {'TemporalFusionTransformer'}\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer']\n",
      "Prediction order: {'ChronosFineTuned[bolt_small]'}\n",
      "\tFine-tuned checkpoint exists, setting model_path to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]']\n",
      "Prediction order: {'RecursiveTabular'}\n",
      "Shortening all series to at most 14507\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular']\n",
      "Prediction order: {'ChronosZeroShot[bolt_small]'}\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular', 'ChronosZeroShot[bolt_small]']\n",
      "Prediction order: {'DirectTabular'}\n",
      "Shortening all series to at most 14497\n",
      "Shortening all series to at most 14495\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Found no cached predictions\n",
      "Prediction order: {'TemporalFusionTransformer'}\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer']\n",
      "Prediction order: {'ChronosFineTuned[bolt_small]'}\n",
      "\tFine-tuned checkpoint exists, setting model_path to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]']\n",
      "Prediction order: {'RecursiveTabular'}\n",
      "Shortening all series to at most 14507\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular']\n",
      "Prediction order: {'ChronosZeroShot[bolt_small]'}\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular', 'ChronosZeroShot[bolt_small]']\n",
      "Prediction order: {'DirectTabular'}\n",
      "Shortening all series to at most 14497\n",
      "Shortening all series to at most 14495\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Found no cached predictions\n",
      "Prediction order: {'TemporalFusionTransformer'}\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer']\n",
      "Prediction order: {'ChronosFineTuned[bolt_small]'}\n",
      "\tFine-tuned checkpoint exists, setting model_path to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]']\n",
      "Prediction order: {'RecursiveTabular'}\n",
      "Shortening all series to at most 14507\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular']\n",
      "Prediction order: {'ChronosZeroShot[bolt_small]'}\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular', 'ChronosZeroShot[bolt_small]']\n",
      "Prediction order: {'DirectTabular'}\n",
      "Shortening all series to at most 14497\n",
      "Shortening all series to at most 14495\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Found no cached predictions\n",
      "Prediction order: {'TemporalFusionTransformer'}\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer']\n",
      "Prediction order: {'ChronosFineTuned[bolt_small]'}\n",
      "\tFine-tuned checkpoint exists, setting model_path to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]']\n",
      "Prediction order: {'RecursiveTabular'}\n",
      "Shortening all series to at most 14507\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular']\n",
      "Prediction order: {'ChronosZeroShot[bolt_small]'}\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular', 'ChronosZeroShot[bolt_small]']\n",
      "Prediction order: {'DirectTabular'}\n",
      "Shortening all series to at most 14497\n",
      "Shortening all series to at most 14495\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Found no cached predictions\n",
      "Prediction order: {'TemporalFusionTransformer'}\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer']\n",
      "Prediction order: {'ChronosFineTuned[bolt_small]'}\n",
      "\tFine-tuned checkpoint exists, setting model_path to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/ChronosFineTuned[bolt_small]/fine-tuned-ckpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]']\n",
      "Prediction order: {'RecursiveTabular'}\n",
      "Shortening all series to at most 14507\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular']\n",
      "Prediction order: {'ChronosZeroShot[bolt_small]'}\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/config.json\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"ChronosBoltModelForForecasting\"\n",
      "  ],\n",
      "  \"chronos_config\": {\n",
      "    \"context_length\": 2048,\n",
      "    \"input_patch_size\": 16,\n",
      "    \"input_patch_stride\": 16,\n",
      "    \"prediction_length\": 64,\n",
      "    \"quantiles\": [\n",
      "      0.1,\n",
      "      0.2,\n",
      "      0.3,\n",
      "      0.4,\n",
      "      0.5,\n",
      "      0.6,\n",
      "      0.7,\n",
      "      0.8,\n",
      "      0.9\n",
      "    ],\n",
      "    \"use_reg_token\": true\n",
      "  },\n",
      "  \"chronos_pipeline_class\": \"ChronosBoltPipeline\",\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 0.05,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"reg_token_id\": 1,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/nikita/.cache/huggingface/hub/models--autogluon--chronos-bolt-small/snapshots/94d26f8f14f17f8c7c6ddf01521a959d4722bc6e/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating ChronosBoltModelForForecasting model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing ChronosBoltModelForForecasting.\n",
      "\n",
      "All the weights of ChronosBoltModelForForecasting were initialized from the model checkpoint at autogluon/chronos-bolt-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ChronosBoltModelForForecasting for predictions without further training.\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n",
      "Loaded cached predictions for models ['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular', 'ChronosZeroShot[bolt_small]']\n",
      "Prediction order: {'DirectTabular'}\n",
      "Shortening all series to at most 14497\n",
      "Shortening all series to at most 14495\n",
      "Extending existing cached predictions\n",
      "Cached predictions saved to /home/nikita/projects/time_series_analysis/code_dir/rosstat/models/auto_ml_single_target/models/cached_predictions.pkl\n"
     ]
    }
   ],
   "source": [
    "def extract_specific_rows_from_indexed_data(data, start_row: int, end_row: int):\n",
    "    rows_to_extract = np.arange(start_row, end_row)\n",
    "    unique_ids = data.index.get_level_values('item_id').unique()\n",
    "        \n",
    "    selected_data = []\n",
    "\n",
    "    for item_id in unique_ids:\n",
    "        item_data = data.loc[[item_id]]\n",
    "        \n",
    "        selected_rows = item_data.iloc[rows_to_extract]\n",
    "        selected_data.append(selected_rows)\n",
    "\n",
    "    result = pd.concat(selected_data)\n",
    "\n",
    "    return result\n",
    "\n",
    "k = 12\n",
    "\n",
    "top_k_models = leaderboard.sort_values(['SQL'], ascending=False).head(k)['model'].tolist()\n",
    "window_size = config.prediction_length\n",
    "test_length = test_df['code'].value_counts().iloc[0]\n",
    "max_iterations = (test_length + window_size - 1) // window_size# - 1 ещё -1 из-за known_covariates\n",
    "\n",
    "current_data = train_data.copy()\n",
    "all_val_models_predictions = {}\n",
    "\n",
    "for i in range(max_iterations):\n",
    "    start_idx = i * window_size\n",
    "    end_idx = start_idx + window_size\n",
    "    \n",
    "    for model_name in top_k_models:\n",
    "        if model_name not in all_val_models_predictions:\n",
    "            all_val_models_predictions[model_name] = []\n",
    "        \n",
    "        # future_covariates = test_data[start_idx:start_idx + config.prediction_length][known_covariates_names]\n",
    "        # prediction_covariates = pd.concat([current_data[known_covariates_names], future_covariates])\n",
    "        \n",
    "        predictions = predictor.predict(current_data, \n",
    "                                       model=model_name,)\n",
    "                                       # known_covariates=prediction_covariates)\n",
    "                                       \n",
    "        all_val_models_predictions[model_name].append(predictions)\n",
    "        \n",
    "    current_data = pd.concat([current_data, extract_specific_rows_from_indexed_data(val_data, start_idx, end_idx)])\n",
    "\n",
    "test_df_shape = test_df.shape[0]\n",
    "all_val_models_predictions = {k: pd.concat(v)[:test_df_shape] for k, v in all_val_models_predictions.items()}\n",
    "\n",
    "current_data = val_data.copy()\n",
    "all_test_models_predictions = {}\n",
    "\n",
    "for i in range(max_iterations):\n",
    "    start_idx = i * window_size\n",
    "    end_idx = start_idx + window_size\n",
    "    \n",
    "    for model_name in top_k_models:\n",
    "        if model_name not in all_test_models_predictions:\n",
    "            all_test_models_predictions[model_name] = []\n",
    "        \n",
    "        # future_covariates = test_data[start_idx:start_idx + config.prediction_length][known_covariates_names]\n",
    "        # prediction_covariates = pd.concat([current_data[known_covariates_names], future_covariates])\n",
    "        \n",
    "        predictions = predictor.predict(current_data, \n",
    "                                       model=model_name,)\n",
    "                                       # known_covariates=prediction_covariates)\n",
    "                                       \n",
    "        all_test_models_predictions[model_name].append(predictions)\n",
    "        \n",
    "    current_data = pd.concat([current_data, extract_specific_rows_from_indexed_data(test_data, start_idx, end_idx)])\n",
    "\n",
    "test_df_shape = test_df.shape[0]\n",
    "all_test_models_predictions = {k: pd.concat(v)[:test_df_shape] for k, v in all_test_models_predictions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_forecasts_val_test(\n",
    "    val_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    val_predictions: pd.DataFrame,\n",
    "    test_predictions: dict[str, pd.DataFrame],\n",
    "    start_date: str | None = None,\n",
    "    end_date: str | None = None,\n",
    "    height: int = 300,\n",
    "    width: int = 1400,\n",
    "    item_id: str | None = None,\n",
    "):\n",
    "    model_names = list(test_predictions.keys())\n",
    "    n_models = len(model_names)\n",
    "    rows = int(np.ceil(n_models / 2))\n",
    "    cols = 2\n",
    "    \n",
    "    filtered_val_df = val_df.copy()\n",
    "    filtered_test_df = test_df.copy()\n",
    "    \n",
    "    if start_date is not None and end_date is not None:        \n",
    "        test_mask = (filtered_test_df[\"timestamp\"] >= start_date) & (filtered_test_df[\"timestamp\"] <= end_date)\n",
    "        filtered_test_df = filtered_test_df[test_mask]\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=rows, cols=cols, subplot_titles=model_names, vertical_spacing=0.1\n",
    "    )\n",
    "    \n",
    "    for i, model_name in enumerate(model_names):\n",
    "        row = i // 2 + 1\n",
    "        col = i % 2 + 1\n",
    "\n",
    "        model_val_pred = val_predictions[model_name].copy()\n",
    "        if item_id is not None:\n",
    "            model_val_pred = model_val_pred.loc[item_id]\n",
    "\n",
    "        filtered_val_mean = model_val_pred[\"mean\"].values\n",
    "        filtered_val_upper = model_val_pred[\"0.9\"].values if \"0.9\" in model_val_pred else None\n",
    "        filtered_val_lower = model_val_pred[\"0.1\"].values if \"0.1\" in model_val_pred else None\n",
    "        \n",
    "        model_test_pred = test_predictions[model_name]\n",
    "        if item_id is not None:\n",
    "            model_test_pred = model_test_pred.loc[item_id]\n",
    "        \n",
    "        if start_date is not None and end_date is not None:\n",
    "            test_time_mask = (test_df[\"timestamp\"] >= start_date) & (test_df[\"timestamp\"] <= end_date)\n",
    "            \n",
    "            filtered_test_mean = model_test_pred[\"mean\"].values[test_time_mask]\n",
    "            filtered_test_upper = model_test_pred[\"0.9\"].values[test_time_mask] if \"0.9\" in model_test_pred else None\n",
    "            filtered_test_lower = model_test_pred[\"0.1\"].values[test_time_mask] if \"0.1\" in model_test_pred else None\n",
    "            \n",
    "        else:\n",
    "            filtered_test_mean = model_test_pred[\"mean\"]\n",
    "            filtered_test_upper = model_test_pred[\"0.9\"] if \"0.9\" in model_test_pred else None\n",
    "            filtered_test_lower = model_test_pred[\"0.1\"] if \"0.1\" in model_test_pred else None\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=filtered_val_df[\"timestamp\"],\n",
    "                y=filtered_val_df[\"target\"],\n",
    "                name=\"Validation (actual)\",\n",
    "                line=dict(color=\"blue\"),\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=filtered_val_df[\"timestamp\"],\n",
    "                y=filtered_val_mean,\n",
    "                name=\"Validation (predicted)\",\n",
    "                line=dict(color=\"purple\", dash=\"dot\"),\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=filtered_test_df[\"timestamp\"],\n",
    "                y=filtered_test_df[\"target\"],\n",
    "                name=\"Test (actual)\",\n",
    "                line=dict(color=\"#50C878\"),\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=filtered_test_df[\"timestamp\"],\n",
    "                y=filtered_test_mean,\n",
    "                name=f\"{model_name} Test (predicted)\",\n",
    "                line=dict(color=\"#D70040\", dash=\"dot\"),\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=filtered_val_df[\"timestamp\"],\n",
    "                    y=filtered_val_upper,\n",
    "                    mode=\"lines\",\n",
    "                    line=dict(width=0),\n",
    "                    showlegend=False,\n",
    "                ),\n",
    "                row=row,\n",
    "                col=col,\n",
    "            )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=filtered_val_df[\"timestamp\"],\n",
    "                y=filtered_val_lower,\n",
    "                mode=\"lines\",\n",
    "                fill=\"tonexty\",\n",
    "                fillcolor=\"rgba(128, 0, 128, 0.6)\",\n",
    "                line=dict(width=0),\n",
    "                name=f\"{model_name} CI (0.1-0.9)\",\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "        \n",
    "        if filtered_test_upper is not None and filtered_test_lower is not None:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=filtered_test_df[\"timestamp\"],\n",
    "                    y=filtered_test_upper,\n",
    "                    mode=\"lines\",\n",
    "                    line=dict(width=0),\n",
    "                    showlegend=False,\n",
    "                ),\n",
    "                row=row,\n",
    "                col=col,\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=filtered_test_df[\"timestamp\"],\n",
    "                    y=filtered_test_lower,\n",
    "                    mode=\"lines\",\n",
    "                    fill=\"tonexty\",\n",
    "                    fillcolor=\"rgba(255, 127, 14, 0.6)\",\n",
    "                    line=dict(width=0),\n",
    "                    name=f\"{model_name} CI (0.1-0.9)\",\n",
    "                ),\n",
    "                row=row,\n",
    "                col=col,\n",
    "            )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Forecasts with Validation and Test Data\",\n",
    "        template=\"plotly_white\",\n",
    "        height=height * rows,\n",
    "        width=width,\n",
    "        showlegend=True,\n",
    "    )\n",
    "    \n",
    "    for i in range(1, rows * cols + 1):\n",
    "        fig.update_xaxes(\n",
    "            title_text=\"Date\",\n",
    "            row=i // cols + 1,\n",
    "            col=i % cols if i % cols != 0 else cols,\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            title_text=\"National Demand\",\n",
    "            row=i // cols + 1,\n",
    "            col=i % cols if i % cols != 0 else cols,\n",
    "        )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0df41537ab6438bbbd5ce00c5fa8871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(DatePicker(value=datetime.date(2023, 1, 1), description='Start date:'), DatePick…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e17eb42ce74a4999252c5ca0af0a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import datetime\n",
    "from utils.plotting import plot_forecasts\n",
    "\n",
    "date_col = pd.to_datetime(test_df[\"date\"])\n",
    "min_date = date_col.min().date()\n",
    "max_date = date_col.max().date()\n",
    "height = 400\n",
    "width = 1200\n",
    "\n",
    "start_date_picker = widgets.DatePicker(\n",
    "    description=\"Start date:\", disabled=False, value=min_date\n",
    ")\n",
    "\n",
    "end_date_picker = widgets.DatePicker(\n",
    "    description=\"End date:\", disabled=False, value=max_date\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        start_date = datetime.datetime.combine(\n",
    "            start_date_picker.value, datetime.datetime.min.time()\n",
    "        )\n",
    "        end_date = datetime.datetime.combine(\n",
    "            end_date_picker.value, datetime.datetime.min.time()\n",
    "        )\n",
    "        plot_forecasts_val_test(\n",
    "            val_df=val_df_,\n",
    "            test_df=test_df_,\n",
    "            val_predictions=all_val_models_predictions_,\n",
    "            test_predictions=all_test_models_predictions,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            height=height,\n",
    "            width=width,\n",
    "            item_id=item_id,\n",
    "        )\n",
    "\n",
    "\n",
    "plot_button = widgets.Button(description=\"Plot Forecasts\")\n",
    "plot_button.on_click(on_button_clicked)\n",
    "\n",
    "controls = widgets.VBox(\n",
    "    [widgets.HBox([start_date_picker, end_date_picker]), plot_button]\n",
    ")\n",
    "\n",
    "display(controls, output_area)\n",
    "\n",
    "# item_id='82.91'\n",
    "# item_id='01.11.39'\n",
    "item_id='82.99'\n",
    "item_id = 81\n",
    "\n",
    "val_df_ = val_df.rename(columns={'date': 'timestamp', \"nominal_wage\": \"target\"})[['code', 'timestamp', \"target\"]]\n",
    "val_df_ = val_df_[val_df_['code'].eq(item_id)].reset_index(drop=True)\n",
    "val_df_['timestamp'] = pd.to_datetime(val_df_['timestamp'])\n",
    "\n",
    "test_df_ = test_df.rename(columns={'date': 'timestamp', \"nominal_wage\": \"target\"})[['code', 'timestamp', \"target\"]]\n",
    "test_df_ = test_df_[test_df_['code'].eq(item_id)].reset_index(drop=True)\n",
    "test_df_['timestamp'] = pd.to_datetime(test_df_['timestamp'])\n",
    "\n",
    "val_df_ = pd.concat([val_df_, test_df_.iloc[[0]]])\n",
    "\n",
    "all_val_models_predictions_ = all_val_models_predictions.copy()\n",
    "for model in all_val_models_predictions_.keys():\n",
    "    all_val_models_predictions_[model] = pd.concat([all_val_models_predictions_[model], all_test_models_predictions[model].loc[[item_id]].iloc[[0]]])\n",
    "\n",
    "with output_area:\n",
    "    plot_forecasts_val_test(\n",
    "        val_df=val_df_,\n",
    "        test_df=test_df_,\n",
    "        val_predictions=all_val_models_predictions_,\n",
    "        test_predictions=all_test_models_predictions,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        item_id=item_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_codes = test_df['code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "nominal_wage",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "dc495bd2-5d89-42e3-b8be-ecd3e79afe12",
       "rows": [
        [
         "12",
         "45308.4"
        ],
        [
         "13",
         "48720.4"
        ],
        [
         "14",
         "49383.2"
        ],
        [
         "15",
         "49534.2"
        ],
        [
         "16",
         "48433.7"
        ],
        [
         "17",
         "50774.0"
        ],
        [
         "18",
         "53697.0"
        ],
        [
         "19",
         "51631.7"
        ],
        [
         "20",
         "54851.8"
        ],
        [
         "21",
         "55021.4"
        ],
        [
         "22",
         "51789.0"
        ],
        [
         "23",
         "70649.2"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nominal_wage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>45308.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>48720.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>49383.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>49534.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>48433.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50774.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>51631.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>54851.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>55021.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>51789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>70649.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nominal_wage\n",
       "12       45308.4\n",
       "13       48720.4\n",
       "14       49383.2\n",
       "15       49534.2\n",
       "16       48433.7\n",
       "17       50774.0\n",
       "18       53697.0\n",
       "19       51631.7\n",
       "20       54851.8\n",
       "21       55021.4\n",
       "22       51789.0\n",
       "23       70649.2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df[\"code\"].eq(code)][[\"nominal_wage\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['TemporalFusionTransformer', 'ChronosFineTuned[bolt_small]', 'RecursiveTabular', 'ChronosZeroShot[bolt_small]', 'DirectTabular'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_models_predictions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_metrics = {}\n",
    "\n",
    "for model in all_test_models_predictions.keys():\n",
    "    metrics_df = []\n",
    "    for code in all_codes:\n",
    "        pred_df = pd.concat([\n",
    "            all_test_models_predictions[model]\n",
    "            .loc[code][[\"0.1\", \"0.5\", \"0.9\"]]\n",
    "            .reset_index(drop=True),\n",
    "            test_df[test_df[\"code\"].eq(code)][[\"nominal_wage\"]].reset_index(drop=True),\n",
    "        ], axis=1)\n",
    "        pred_df = pd.DataFrame(pred_df)\n",
    "\n",
    "        metrics_df.append(calculate_sklearn_metrics(pred_df, target_column='nominal_wage'))\n",
    "\n",
    "    metrics_dict = pd.DataFrame(metrics_df).mean().to_dict()\n",
    "\n",
    "    all_models_metrics[model] = metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run TemporalFusionTransformer_AutoGluon at: http://127.0.0.1:5000/#/experiments/169882278836627198/runs/8c618c134b454ba68f2aa7d8b015048e\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/169882278836627198\n",
      "🏃 View run ChronosFineTuned[bolt_small]_AutoGluon at: http://127.0.0.1:5000/#/experiments/169882278836627198/runs/a43e818d33274e17aecae589c54e5562\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/169882278836627198\n",
      "🏃 View run RecursiveTabular_AutoGluon at: http://127.0.0.1:5000/#/experiments/169882278836627198/runs/f8fedfd1a3374defa0b511dcac72c4d9\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/169882278836627198\n",
      "🏃 View run ChronosZeroShot[bolt_small]_AutoGluon at: http://127.0.0.1:5000/#/experiments/169882278836627198/runs/970f5e30ef45474fb87a664037410031\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/169882278836627198\n",
      "🏃 View run DirectTabular_AutoGluon at: http://127.0.0.1:5000/#/experiments/169882278836627198/runs/18a041662fd149d3a896e521b6f3eb83\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/169882278836627198\n"
     ]
    }
   ],
   "source": [
    "prefix = 'AutoGluon'\n",
    "\n",
    "for k, metrics_ in all_models_metrics.items():\n",
    "    run_name = f\"{k}_{prefix}\"\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_metrics(metrics_)\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "\n",
    "        mlflow.set_tag(\"prefix\", prefix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
